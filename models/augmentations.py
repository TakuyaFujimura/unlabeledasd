# Copyright 2024 Takuya Fujimura

import copy

import torch
from torch import nn


def rand_uniform_tensor(tensor_size, min_val, max_val):
    x = torch.rand(tensor_size) * (max_val - min_val)
    x = x + min_val
    return x


def mix_with_snr(target, noise, snr, signal_power=1):
    """Returns a noisy signal
    Args:
        target (tensor): target. (B, F, T) or (B, T)
        noise (tensor): noise. (B, F, T) or (B, T)
        snr (tensor): noise. (B)
    Returns:
        noisy (tensor): noisy signal generated by mixing target and noise. (B, F, T)
    """
    assert len(target.shape) == len(noise.shape)
    if len(target.shape) == 3:
        dim = (1, 2)
    else:
        assert len(target.shape) == 2
        dim = (1,)
    Ps_batch = torch.mean(torch.abs(target) ** (2 / signal_power), dim=dim)
    Pn_batch = torch.mean(torch.abs(noise) ** (2 / signal_power), dim=dim)
    c = torch.sqrt(Ps_batch / (Pn_batch * 10 ** (snr / 10)))

    if len(target.shape) == 3:
        c = c[:, None, None]
    else:
        c = c[:, None]
    return target + c * noise


def mix_rand_snr(target, noise, min_snr, max_snr, signal_power=1):
    """Returns a noisy signal
    Args:
        target (tensor): target. (B, F, T) or (B, T)
        noise (tensor): noise. (B, F, T) or (B, T)
    Returns:
        noisy (tensor): noisy signal generated by mixing target and noise. (B, F, T)
    """
    snr = rand_uniform_tensor([len(target)], min_snr, max_snr)
    snr = snr.to(target.device)
    return mix_with_snr(target, noise, snr, signal_power)


def get_perm(B, device):
    perm = torch.randperm(B).to(device)
    return perm


class MixupLayer(nn.Module):
    def __init__(self, prob, label_candidate):
        super().__init__()
        self.prob = prob
        self.label_candidate = label_candidate

    @staticmethod
    def process(lam, perm, dec, data):
        lam = lam.reshape([-1] + [1] * (len(data.shape) - 1))
        dec = dec.reshape([-1] + [1] * (len(data.shape) - 1))
        data_mix = lam * data + (1 - lam) * data[perm]
        result = dec * data_mix + (1 - dec) * data
        return result

    def forward(self, X_org, labels_org, is_applied=True):
        if not self.training or not is_applied:
            return X_org, labels_org
        lam = torch.rand(len(X_org), device=X_org.device)
        perm = get_perm(len(X_org), X_org.device)
        dec = torch.rand(len(X_org), device=X_org.device) < self.prob
        dec = dec.float()

        X_mix = self.process(lam, perm, dec, X_org)
        labels_mix = {}
        for key_ in self.label_candidate:
            labels_mix[key_] = self.process(lam, perm, dec, labels_org[key_])
        return X_mix, labels_mix


class StatExLayer(nn.Module):
    def __init__(self, prob, label_candidate):
        super().__init__()
        self.prob = prob
        self.label_candidate = label_candidate

    @staticmethod
    def process_X(perm, dec, X):
        dec = dec.reshape([-1] + [1] * (len(X.shape) - 1))
        X_rev = X[perm]
        X_tex = (
            (X - X.mean(dim=2, keepdim=True)) / (X.std(dim=2, keepdim=True) + 1e-6)
        ) * X_rev.std(dim=2, keepdim=True) + X_rev.mean(dim=2, keepdim=True)
        X_fex = (
            (X - X.mean(dim=1, keepdim=True)) / (X.std(dim=1, keepdim=True) + 1e-6)
        ) * X_rev.std(dim=1, keepdim=True) + X_rev.mean(dim=1, keepdim=True)
        dec_ft = torch.rand(len(X), device=X.device) < 0.5
        dec_ft = dec_ft.reshape([-1] + [1] * (len(X.shape) - 1)).float()
        X_ex = dec_ft * X_tex + (1 - dec_ft) * X_fex
        result = dec * X_ex + (1 - dec) * X
        return result

    @staticmethod
    def process_label(perm, dec, label):
        dec = dec.reshape([-1] + [1] * (len(label.shape) - 1))
        label_ex = torch.cat(
            [torch.zeros_like(label), 0.5 * label, 0.5 * label[perm]], dim=1
        )
        label_pad = torch.cat(
            [label, torch.zeros_like(label), torch.zeros_like(label)], dim=1
        )
        result = dec * label_ex + (1 - dec) * label_pad
        return result

    def pad_labels(self, labels_org):
        labels_pad = {}
        for key_ in self.label_candidate:
            if key_ in labels_org:
                labels_pad[key_] = torch.cat(
                    [
                        labels_org[key_],
                        torch.zeros_like(labels_org[key_]),
                        torch.zeros_like(labels_org[key_]),
                    ],
                    dim=1,
                )
        return labels_pad

    def forward(self, X_org, labels_org, is_applied=True):
        if not self.training or not is_applied:
            return X_org, self.pad_labels(labels_org)

        dec = torch.rand(len(X_org), device=X_org.device) < self.prob
        dec = dec.float()
        perm = get_perm(len(X_org), X_org.device)

        X_ex = self.process_X(perm, dec, X_org)
        labels_ex = {}
        for key_ in self.label_candidate:
            labels_ex[key_] = self.process_label(perm, dec, labels_org[key_])

        return X_ex, labels_ex


class FeatExLayer(nn.Module):
    def __init__(self, prob, label_candidate, emb_num):
        super().__init__()
        self.prob = prob
        self.label_candidate = label_candidate
        self.emb_num = emb_num

    def process_emb(self, dec, perm_list, emb_list):
        dec = dec.reshape([-1] + [1] * (len(emb_list[0].shape) - 1))
        emb_org = torch.cat(emb_list, dim=-1)
        emb_ex = torch.cat([emb[perm] for emb, perm in zip(emb_list, perm_list)], dim=1)
        return dec * emb_ex + (1 - dec) * emb_org

    def pad_label(self, label):
        return torch.cat(
            [label] + [torch.zeros_like(label) for _ in range(self.emb_num)],
            dim=-1,
        )

    def process_label(self, dec, perm_list, label):
        dec = dec.reshape([-1] + [1] * (len(label.shape) - 1))
        label_ex = torch.cat(
            [torch.zeros_like(label)]
            + [label[perm] / self.emb_num for perm in perm_list],
            dim=-1,
        )
        label_pad = self.pad_label(label)
        result = dec * label_ex + (1 - dec) * label_pad
        return result

    def pad_label_dict(self, label_dict):
        labels_pad = {}
        for key_ in self.label_candidate:
            if key_ in label_dict:
                labels_pad[key_] = self.pad_label(label_dict[key_])
        return labels_pad

    def forward(self, emb_list, labels_org, is_applied=True):
        if not self.training or not is_applied:
            return torch.cat(emb_list, dim=-1), self.pad_label_dict(labels_org)

        dec = torch.rand(len(emb_list[0]), device=emb_list[0].device) < self.prob
        dec = dec.float()
        perm_list = [
            get_perm(len(emb_list[0]), emb_list[0].device) for _ in range(self.emb_num)
        ]

        emb_ex = self.process_emb(dec, perm_list, emb_list)
        labels_ex = {}
        for key_ in self.label_candidate:
            labels_ex[key_] = self.process_label(dec, perm_list, labels_org[key_])
        return emb_ex, labels_ex


class CutMixLayer(nn.Module):
    def __init__(self, prob, label_candidate):
        super().__init__()
        self.prob = prob
        self.label_candidate = label_candidate

    @staticmethod
    def process_time(lam, perm, dec, data):
        assert len(data.shape) == 2
        all_len = data.shape[-1]
        crop_len = ((1 - lam) * all_len).type(torch.int32)
        data_mix = copy.deepcopy(data)
        for i in range(len(data)):
            if dec[i] == 1.0:
                start = torch.randint(0, max(1, all_len - crop_len[i]), (1,))[0]
                data_mix[i, start : start + crop_len[i]] = data[
                    perm[i], start : start + crop_len[i]
                ]
        return data_mix

    @staticmethod
    def process_label(lam, perm, dec, data):
        lam = lam.reshape([-1] + [1] * (len(data.shape) - 1))
        dec = dec.reshape([-1] + [1] * (len(data.shape) - 1))
        data_mix = lam * data + (1 - lam) * data[perm]
        result = dec * data_mix + (1 - dec) * data
        return result

    def forward(self, X_org, labels_org, is_applied=True):
        # X is wave
        if not self.training or not is_applied:
            return X_org, labels_org
        lam = torch.rand(len(X_org), device=X_org.device)
        perm = get_perm(len(X_org), X_org.device)
        dec = torch.rand(len(X_org), device=X_org.device) < self.prob
        dec = dec.float()
        X_mix = self.process_time(lam, perm, dec, X_org)
        labels_mix = {}
        for key_ in self.label_candidate:
            labels_mix[key_] = self.process_label(lam, perm, dec, labels_org[key_])
        return X_mix, labels_mix
